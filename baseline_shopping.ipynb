{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haeuni7/coding-practice/blob/main/baseline_shopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41196da1-2198-44a5-b93f-9bb8335bcf15"
      },
      "source": [
        "# 쇼핑 고객 상담 대화 문장 의도 태깅\n",
        "\n",
        "- 2차 모의경진대회(22.11.28 ~ 22.12.25)\n",
        "- Text Classification 과제"
      ],
      "id": "41196da1-2198-44a5-b93f-9bb8335bcf15"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pgSg-Imnq3x"
      },
      "source": [
        "## 디렉터리 구조\n",
        "```\n",
        "$ Shopping/\n",
        "├── DATA/\n",
        "│    ├── train/\n",
        "│    │    ├── texts/\n",
        "│    │    │    ├── shopping1_0001.txt\n",
        "│    │    │    ├── ...\n",
        "│    │    │    └── shopping7_2536.txt\n",
        "│    │    └── labels/\n",
        "│    │          ├── shopping1_0001.json\n",
        "│    │          ├── ...\n",
        "│    │          └── shopping7_2536.json\n",
        "│    ├── test/\n",
        "│    │    └── texts/\n",
        "│    │          ├── test_0001.txt\n",
        "│    │          ├── ...\n",
        "│    │          └── test_1456.txt\n",
        "│    └── sample_submission.csv\n",
        "│\n",
        "└── baseline/\n",
        "      ├── config/\n",
        "      │    ├── train.yaml\n",
        "      │    └── predict.yaml\n",
        "      │── modules/\n",
        "      │    ├── earlystopper.py\n",
        "      │    ├── losses.py\n",
        "      │    ├── recorders.py\n",
        "      │    └── utils.py\n",
        "      ├── results/\n",
        "      │    └── train/\n",
        "      ├── wandb/ # wandb 최초 사용 후 생성\n",
        "      ├── baseline_shopping.ipynb\n",
        "      └── submission.csv (코드 실행 후 생성되는 추론 파일)\n",
        "\n",
        "```\n",
        "    - config : 학습/추론에 필요한 파라미터 등을 기록하는 yaml 파일\n",
        "    - modules\n",
        "        - earlystopper.py : loss가 특정 에폭 이상 개선되지 않을 경우 학습을 멈춤\n",
        "        - losses.py : config에서 지정한 loss function을 리턴\n",
        "        - recorders.py : log, learning curve, best model.pt 등을 기록\n",
        "        - utils.py : 여러 확장자 파일을 불러오거나 여러 확장자로 저장하는 등의 함수\n",
        "    - results\n",
        "      - train/ : 학습 log, 추론 log를 기록하는 디렉토리\n",
        "    - baseline_shopping.ipynb : 전처리부터 학습, 추론까지 수행할 코드 \n",
        "\n",
        "## 노트북 실행 요령\n",
        "- 해당 베이스라인 코드는 [Wandb](https://wandb.ai/site) 를 활용한 실험 관리가 가능합니다.\n",
        "- 해당 베이스라인 코드 실행 전 `config/train.yaml`을 수정하세요.\n",
        "- 해당 베이스라인 코드의 추론 실행 전 `config/predict.yaml`을 수정하세요.\n",
        "- 학습 결과는 `results/train/train_serial` 에 저장되며, wandb를 통해 학습 그래프를 확인하실 수 있습니다."
      ],
      "id": "8pgSg-Imnq3x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v-ms2L0KK0M"
      },
      "source": [
        "#0. 사전 준비"
      ],
      "id": "9v-ms2L0KK0M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa9Mx1ZMKPkv"
      },
      "source": [
        "### 구글 드라이브 마운트"
      ],
      "id": "wa9Mx1ZMKPkv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wdxa3N8NO3A",
        "outputId": "7177d2f2-6e0f-4a0b-a0b7-b43e27fb4a59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 구글 Colaboratory 를 사용하기 위해 구글 계정으로 로그인합니다. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "4wdxa3N8NO3A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MEzQP3GPrDd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Shopping/')"
      ],
      "id": "-MEzQP3GPrDd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f186a6a3-e5e4-41a4-bb3e-89c64aa01910"
      },
      "source": [
        "### 라이브러리 설치"
      ],
      "id": "f186a6a3-e5e4-41a4-bb3e-89c64aa01910"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42f536b6-3347-4252-a704-607de720c21e",
        "outputId": "18af0c75-15dd-4874-ebc1-09ebeb92dd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.8/dist-packages (2.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf) (6.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.8/dist-packages (from omegaconf) (4.9.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (0.13.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.0.11)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.9.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.1.29)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install omegaconf\n",
        "!pip install wandb"
      ],
      "id": "42f536b6-3347-4252-a704-607de720c21e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55fee252-995d-448b-93d5-6ca72a4f68f3"
      },
      "source": [
        " # 1. Import"
      ],
      "id": "55fee252-995d-448b-93d5-6ca72a4f68f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48569888-879e-4e14-8220-454dc06b73f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import wandb\n",
        "import shutil\n",
        "import random\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "from sklearn.metrics import f1_score\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils import *\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import logging, get_linear_schedule_with_warmup\n",
        "from transformers import ( \n",
        "    BertConfig,\n",
        "    ElectraConfig\n",
        ")\n",
        "\n",
        "\n",
        "# 실험에 사용할 모델 라이브러리 추가\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertTokenizerFast,\n",
        "    AutoTokenizer,\n",
        "    ElectraTokenizer,\n",
        "    AlbertTokenizer,\n",
        "    RobertaTokenizerFast\n",
        ")\n",
        "from transformers import (\n",
        "    BertModel,\n",
        "    AutoModel, \n",
        "    ElectraForSequenceClassification,\n",
        "    BertForSequenceClassification,\n",
        "    AlbertForSequenceClassification,\n",
        "    RobertaForSequenceClassification,\n",
        "    TextClassificationPipeline\n",
        ")"
      ],
      "id": "48569888-879e-4e14-8220-454dc06b73f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3423814c-c555-4992-8f37-4886afa8fe86"
      },
      "source": [
        "# 2. 실험 세팅 \n",
        "### Train Configuration"
      ],
      "id": "3423814c-c555-4992-8f37-4886afa8fe86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "059bba81-155c-4fe8-af14-1ee8ee8d94f1",
        "outputId": "7f7eb642-176b-46d8-a56c-6df2833e211b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT_DIR : /content/drive/MyDrive/Shopping\n"
          ]
        }
      ],
      "source": [
        "# Project directory\n",
        "PROJECT_DIR = os.getcwd()\n",
        "print('PROJECT_DIR :',PROJECT_DIR)\n",
        "\n",
        "# Load train config\n",
        "## !!! config 수정할때마다 이 셀을 다시 실행하세요 !!!\n",
        "config_path = os.path.join(PROJECT_DIR, 'baseline', 'config', 'train.yaml')\n",
        "config = OmegaConf.load(config_path)"
      ],
      "id": "059bba81-155c-4fe8-af14-1ee8ee8d94f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc69bd47-35c2-4119-aefd-923b34f98426"
      },
      "source": [
        "### 실험 기록 및 경로 설정"
      ],
      "id": "fc69bd47-35c2-4119-aefd-923b34f98426"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6655c514-58ef-4c7e-8ed9-9e8596adc003",
        "outputId": "c4a27377-e158-4b58-e878-ebb7752cf5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results will be found here :  /content/drive/MyDrive/Shopping/results/train/20221019_180402\n",
            "DATA_DIR : /content/drive/MyDrive/Shopping/DATA\n",
            "TRAIN_DIR : /content/drive/MyDrive/Shopping/DATA/train\n",
            "TEST_DIR : /content/drive/MyDrive/Shopping/DATA/test\n",
            "SAMPLE_DIR : /content/drive/MyDrive/Shopping/DATA/sample_submission.csv\n"
          ]
        }
      ],
      "source": [
        "# Train Serial\n",
        "kst = timezone(timedelta(hours=9))\n",
        "train_serial = datetime.now(tz=kst).strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "\n",
        "# Recorder directory\n",
        "if config.train.resume==None:\n",
        "    RECORDER_DIR = os.path.join(PROJECT_DIR, 'results', 'train', train_serial)\n",
        "else:\n",
        "    RECORDER_DIR = os.path.join(PROJECT_DIR, config.train.resume_weight_dir)\n",
        "    \n",
        "os.makedirs(RECORDER_DIR, exist_ok=True)\n",
        "print(\"Results will be found here : \", RECORDER_DIR)\n",
        "\n",
        "# Data Directory\n",
        "DATA_DIR = Path(config.train.dataset_path)\n",
        "TRAIN_DIR = DATA_DIR/'train/'\n",
        "TEST_DIR = DATA_DIR/'test/'\n",
        "SAMPLE_DIR = os.path.join(DATA_DIR,'sample_submission.csv')\n",
        "\n",
        "print('DATA_DIR :',DATA_DIR)\n",
        "print('TRAIN_DIR :',TRAIN_DIR)\n",
        "print('TEST_DIR :',TEST_DIR)\n",
        "print('SAMPLE_DIR :',SAMPLE_DIR)"
      ],
      "id": "6655c514-58ef-4c7e-8ed9-9e8596adc003"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64f73a37-0f4e-4ff8-a9df-bf580e894f42"
      },
      "source": [
        "### Seed 고정 및 GPU 지정"
      ],
      "id": "64f73a37-0f4e-4ff8-a9df-bf580e894f42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48df682e-bd21-4a51-833f-1115166d8bc1",
        "outputId": "52732bba-8623-4484-c067-caa3ae998058"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Seed 설정\n",
        "random.seed(config.train.seed)\n",
        "np.random.seed(config.train.seed)\n",
        "torch.manual_seed(config.train.seed)\n",
        "torch.cuda.manual_seed_all(config.train.seed)\n",
        "\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "id": "48df682e-bd21-4a51-833f-1115166d8bc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79b2fe59-0197-44ed-8ba7-68c988b2747f"
      },
      "source": [
        "### Set logger"
      ],
      "id": "79b2fe59-0197-44ed-8ba7-68c988b2747f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6de5e92-2781-487a-b2b9-1f71665d9d0f",
        "outputId": "c6862869-2cfb-45a7-bd63-732b085ae2e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:train:Set Logger /content/drive/MyDrive/Shopping/results/train/20221019_180402\n",
            "INFO:train:train:\n",
            "  dataset_path: /content/drive/MyDrive/Shopping/DATA\n",
            "  num_classes: 14\n",
            "  max_seq_len: 128\n",
            "  train_batch_size: 32\n",
            "  eval_batch_size: 32\n",
            "  num_epochs: 5\n",
            "  metric: f1\n",
            "  seed: 777\n",
            "  early_stopping_patience: 2\n",
            "  resume: true\n",
            "  resume_weight_dir: results/train/20221019_180402\n",
            "  save_strategy: epoch\n",
            "  save_steps: 100\n",
            "  eval_steps: 500\n",
            "  evaluation_strategy: epoch\n",
            "  fp16: true\n",
            "  num_workers: 1\n",
            "  use_cuda: true\n",
            "  gpus: '1'\n",
            "  optimizer: adam\n",
            "  adam_epsilon: 1.0e-08\n",
            "  warmup_proportion: 0.04\n",
            "  learning_rate: 0.0001\n",
            "  weight_decay: 0.01\n",
            "  wandb: true\n",
            "  logging_strategy: epoch\n",
            "  logging_steps: 200\n",
            "model:\n",
            "  pretrained_model: klue/roberta-large\n",
            "  architecture: RobertaForSequenceClassification\n",
            "  tokenizer_class: BertTokenizer\n",
            "\n"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/drive/MyDrive/Shopping/baseline')\n",
        "from modules.utils import get_logger\n",
        "\n",
        "logger = get_logger(name='train', dir_=RECORDER_DIR, stream=False)\n",
        "logger.info(f\"Set Logger {RECORDER_DIR}\")\n",
        "logger.info(OmegaConf.to_yaml(config))"
      ],
      "id": "d6de5e92-2781-487a-b2b9-1f71665d9d0f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899bc951-851a-43ea-95e9-49fa4e2fa0c9"
      },
      "source": [
        "# 3. EDA 및 데이터 전처리\n",
        "### DataFrame으로 시각화"
      ],
      "id": "899bc951-851a-43ea-95e9-49fa4e2fa0c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "551d2840-11f9-4e27-adbe-4b998bb9c508"
      },
      "outputs": [],
      "source": [
        "def make_df(data_dir:Path, test=False):\n",
        "    sentence_id=[]     # 파일명 + .txt + 텍스트 내에서 문장 순서\n",
        "    speaker = []       # 화자\n",
        "    text = []          # text\n",
        "    speechAct = []     # 문장이 어떤 내용인지 말해주는 label값\n",
        "    \n",
        "    for directory in data_dir.iterdir():\n",
        "        for file in directory.iterdir():\n",
        "            if 'checkpoint' in str(file): continue\n",
        "            if test ==False:\n",
        "                try:\n",
        "                    label = json.load(open(file))\n",
        "                except:\n",
        "                    continue\n",
        "                lines = label['info'][0]['annotations']['lines']\n",
        "                for i, l in enumerate(lines):\n",
        "                    sentence_id.append(file.stem+'.txt-'+str(i)) # 문장 id\n",
        "                    speaker.append(l['text'].split('.')[0]) # 화자 넣기\n",
        "                    text.append(l['text'].split('.')[-1]) # 화자 구분 빼기\n",
        "                    speechAct.append(l['speechAct'])\n",
        "            elif file.match(\"*.txt\"):\n",
        "                try:\n",
        "                    with open(file, \"r\") as f:\n",
        "                        lines = f.read().splitlines()\n",
        "                        # print(lines)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "                for i, l in enumerate(lines):\n",
        "                    sentence_id.append(file.stem+'.txt-'+str(i))\n",
        "                    speaker.append(l.split('.')[0]) # 화자 넣기\n",
        "                    text.append(l.split('.')[-1]) # 화자 구분 빼기\n",
        "    if test==False:\n",
        "        df = pd.DataFrame({'sentence_id': sentence_id, 'speaker':speaker,'text': text, 'speechAct':speechAct})\n",
        "    else:\n",
        "        df = pd.DataFrame({'sentence_id': sentence_id, 'speaker':speaker,'text': text})\n",
        "\n",
        "    return df"
      ],
      "id": "551d2840-11f9-4e27-adbe-4b998bb9c508"
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df = make_df(TEST_DIR, test=True)\n",
        "# test_df['order']=test_df['sentence_id'].str.split('-')\n",
        "\n",
        "# for i in range(len(test_df)):\n",
        "#     test_df['order'][i][1]=int(test_df['order'][i][1])\n",
        "# test_df.sort_values(by='order',inplace=True)\n",
        "# test_df.reset_index(inplace=True)\n",
        "# test_df.drop(['index', 'speaker', 'order'], axis=1, inplace=True)\n",
        "# test_df"
      ],
      "metadata": {
        "id": "GknrHZxt_BWb"
      },
      "id": "GknrHZxt_BWb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df.drop(['index', 'speaker'], axis=1)"
      ],
      "metadata": {
        "id": "5PdQmPH63rMI"
      },
      "id": "5PdQmPH63rMI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23aa4a5d-fa56-4f1f-a00a-1a14dd6b2e49"
      },
      "outputs": [],
      "source": [
        "train_df = make_df(TRAIN_DIR)"
      ],
      "id": "23aa4a5d-fa56-4f1f-a00a-1a14dd6b2e49"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "8b5d7d3c-f493-4f54-9e8c-9be9b9ae49d5",
        "outputId": "e8c6cdfb-3f73-4d1d-dfe3-9e8af6b429d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  sentence_id speaker                                 text  \\\n",
              "0        shopping1_2424.txt-0       A                   반갑습니다 상담사 #@이름#입니다   \n",
              "1        shopping1_2424.txt-1       B       세탁기 산 지가 아직 일 년이 안 됐는데 고장이 났어요   \n",
              "2        shopping1_2424.txt-2       A                   고객님 세탁기의 종류는 무엇인가요   \n",
              "3        shopping1_2424.txt-3       B                     지금 일반 통돌이 쓰고 있어요   \n",
              "4        shopping1_2424.txt-4       A                        어떤 것이 고장이 났나요   \n",
              "...                       ...     ...                                  ...   \n",
              "189778   shopping3_1565.txt-6       B                   뭐 따로 해야 할 절차가 있을까요   \n",
              "189779   shopping3_1565.txt-7       A                     이 기능을 이용하기 위해서는요   \n",
              "189780   shopping3_1565.txt-8       A  사용할 계좌 인증 및 자동이체 출금 동의 절차를 완료해야 합니다   \n",
              "189781   shopping3_1565.txt-9       B                         네 그렇군요 알겠습니다   \n",
              "189782  shopping3_1565.txt-10       A            네 답변이 도움이 되었기를 바랍니다 감사합니다   \n",
              "\n",
              "       speechAct  \n",
              "0           인사하기  \n",
              "1           진술하기  \n",
              "2           질문하기  \n",
              "3           진술하기  \n",
              "4           질문하기  \n",
              "...          ...  \n",
              "189778      질문하기  \n",
              "189779      진술하기  \n",
              "189780      진술하기  \n",
              "189781      진술하기  \n",
              "189782      감사하기  \n",
              "\n",
              "[189783 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f711a83-ba8a-4c8e-bafd-9bf6fe59b3a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "      <th>speechAct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>shopping1_2424.txt-0</td>\n",
              "      <td>A</td>\n",
              "      <td>반갑습니다 상담사 #@이름#입니다</td>\n",
              "      <td>인사하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>shopping1_2424.txt-1</td>\n",
              "      <td>B</td>\n",
              "      <td>세탁기 산 지가 아직 일 년이 안 됐는데 고장이 났어요</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>shopping1_2424.txt-2</td>\n",
              "      <td>A</td>\n",
              "      <td>고객님 세탁기의 종류는 무엇인가요</td>\n",
              "      <td>질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>shopping1_2424.txt-3</td>\n",
              "      <td>B</td>\n",
              "      <td>지금 일반 통돌이 쓰고 있어요</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shopping1_2424.txt-4</td>\n",
              "      <td>A</td>\n",
              "      <td>어떤 것이 고장이 났나요</td>\n",
              "      <td>질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189778</th>\n",
              "      <td>shopping3_1565.txt-6</td>\n",
              "      <td>B</td>\n",
              "      <td>뭐 따로 해야 할 절차가 있을까요</td>\n",
              "      <td>질문하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189779</th>\n",
              "      <td>shopping3_1565.txt-7</td>\n",
              "      <td>A</td>\n",
              "      <td>이 기능을 이용하기 위해서는요</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189780</th>\n",
              "      <td>shopping3_1565.txt-8</td>\n",
              "      <td>A</td>\n",
              "      <td>사용할 계좌 인증 및 자동이체 출금 동의 절차를 완료해야 합니다</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189781</th>\n",
              "      <td>shopping3_1565.txt-9</td>\n",
              "      <td>B</td>\n",
              "      <td>네 그렇군요 알겠습니다</td>\n",
              "      <td>진술하기</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189782</th>\n",
              "      <td>shopping3_1565.txt-10</td>\n",
              "      <td>A</td>\n",
              "      <td>네 답변이 도움이 되었기를 바랍니다 감사합니다</td>\n",
              "      <td>감사하기</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>189783 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f711a83-ba8a-4c8e-bafd-9bf6fe59b3a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f711a83-ba8a-4c8e-bafd-9bf6fe59b3a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f711a83-ba8a-4c8e-bafd-9bf6fe59b3a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_df"
      ],
      "id": "8b5d7d3c-f493-4f54-9e8c-9be9b9ae49d5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfe1e61a-cb95-49a3-a1ee-0415d5e82bbb"
      },
      "outputs": [],
      "source": [
        "# 라벨을 인코딩할 딕셔너리 (학습에 사용)\n",
        "label2encoding = {Act: ind for ind, Act in enumerate(train_df['speechAct'].unique())}\n",
        "# 인코딩된 라벨을 디코딩할 딕셔너리 (추론에 사용)\n",
        "encoding2label = {idx: Act for idx, Act in enumerate(train_df['speechAct'].unique())}"
      ],
      "id": "bfe1e61a-cb95-49a3-a1ee-0415d5e82bbb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e1a4da2-7464-4564-8df9-38de6e849360",
        "outputId": "01c85540-79b7-4e49-e568-d1f6edaece5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: text, dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 길이가 128이 넘는 코멘트가 있는지 확인\n",
        "train_df['text'][train_df['text'].str.len()>config.train.max_seq_len]"
      ],
      "id": "1e1a4da2-7464-4564-8df9-38de6e849360"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce4062a-7030-4a06-9ec1-985a9e7bd49e"
      },
      "source": [
        "### Tokenizer"
      ],
      "id": "7ce4062a-7030-4a06-9ec1-985a9e7bd49e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ad836f0-27b4-42ac-bb38-99352a077def"
      },
      "outputs": [],
      "source": [
        "# config.json 에서 지정 이름별로 가져올 라이브러리 지정\n",
        "\n",
        "TOKENIZER_CLASSES = {\n",
        "    \"BertTokenizer\": BertTokenizer,\n",
        "    \"BertTokenizerFast\": BertTokenizerFast,\n",
        "    \"AutoTokenizer\": AutoTokenizer,\n",
        "    \"ElectraTokenizer\": ElectraTokenizer,\n",
        "    \"AlbertTokenizer\": AlbertTokenizer,\n",
        "    \"RobertaTokenizerFast\" : RobertaTokenizerFast\n",
        "}\n",
        "TOKENIZER = TOKENIZER_CLASSES[config.model.tokenizer_class].from_pretrained(config.model.pretrained_model)"
      ],
      "id": "7ad836f0-27b4-42ac-bb38-99352a077def"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bfe68a6-f3bc-4182-8666-43588fa12bc1",
        "outputId": "410f9cef-cfeb-4ced-a6b8-0fb6c83c6b14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [0, 9927, 2219, 3606, 4981, 2063, 7, 36, 3934, 7, 3714, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "[0, 9927, 2219, 3606, 4981, 2063, 7, 36, 3934, 7, 3714, 2] \n",
            "\n",
            "['반갑', '##습', '##니다', '상담', '##사', '#', '@', '이름', '#', '입니다'] \n",
            "\n",
            "[9927, 2219, 3606, 4981, 2063, 7, 36, 3934, 7, 3714]\n"
          ]
        }
      ],
      "source": [
        "# Tokenizer 예시\n",
        "comment_ex = train_df['text'][0]\n",
        "print(TOKENIZER(comment_ex))\n",
        "print(TOKENIZER.encode(comment_ex),\"\\n\")\n",
        "\n",
        "# 토큰으로 나누기\n",
        "print(TOKENIZER.tokenize(comment_ex),\"\\n\")\n",
        "\n",
        "# 토큰 id로 매핑하기\n",
        "print(TOKENIZER.convert_tokens_to_ids(TOKENIZER.tokenize(comment_ex)))"
      ],
      "id": "2bfe68a6-f3bc-4182-8666-43588fa12bc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d1f4263-b34c-4d32-9e45-6243bafb018c"
      },
      "source": [
        "# 4. Dataset"
      ],
      "id": "3d1f4263-b34c-4d32-9e45-6243bafb018c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIiEaoZLN-qY"
      },
      "source": [
        "### CustomDataset 클래스 정의"
      ],
      "id": "dIiEaoZLN-qY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00f35f69-d09c-4931-bb2a-298ced956dd3"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):  # 데이터를 input으로 변환해주는 Dataset 클래스를 상속한 후 커스터마이징\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_seq_len, mode = 'train'):  # Dataset 클래스는 기본적으로 __init__, __len__, __getitem__를 정의해 주어야 한다\n",
        "\n",
        "        self.data = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.mode = mode\n",
        "        self.speakers = self.data['speaker'].tolist()\n",
        "        self.texts = self.data['text'].tolist()\n",
        "        \n",
        "        if self.mode!='test':\n",
        "            try: \n",
        "                self.labels = df['speechAct'].tolist()\n",
        "            except:\n",
        "                assert False, 'CustomDataset Error : \\'label\\' column does not exist in the dataframe'\n",
        "     \n",
        "    def __len__(self):  # index를 통해 input을 순차적으로 읽어오기 위해서는 데이터의 길이가 먼저 확인되어야 한다. __len__ 함수는 input의 길이를 반환해주는 함수\n",
        "        return len(self.data)\n",
        "                \n",
        "\n",
        "    def __getitem__(self, idx):  # input의 길이가 확인되면 index를 통해 데이터를 불러올 수 있다. __getitem__ 함수는 index에 해당하는 input 데이터를 반환해주는 함수\n",
        "        \"\"\"\n",
        "        전체 데이터에서 특정 인덱스 (idx)에 해당하는 기사제목과 댓글 내용을 \n",
        "        토크나이즈한 data('input_ids', 'attention_mask','token_type_ids')의 딕셔너리 형태로 불러옴\n",
        "        \"\"\"\n",
        "        tokenized_text = self.tokenizer(self.texts[idx],\n",
        "                             padding= 'max_length',\n",
        "                             max_length=self.max_seq_len,\n",
        "                             truncation=True,\n",
        "                             return_token_type_ids=True,\n",
        "                             return_attention_mask=True,\n",
        "                             return_tensors = \"pt\")\n",
        "\n",
        "        if self.mode=='test':\n",
        "            data = {'input_ids': tokenized_text['input_ids'].squeeze(0).long(),\n",
        "                   'attention_mask': tokenized_text['attention_mask'].squeeze(0).long(),\n",
        "                   'token_type_ids': tokenized_text['token_type_ids'].squeeze(0).long()\n",
        "                    }\n",
        "        else:\n",
        "            data = {'input_ids': tokenized_text['input_ids'].squeeze(0).long(),\n",
        "                   'attention_mask': tokenized_text['attention_mask'].squeeze(0).long(),\n",
        "                   'token_type_ids': tokenized_text['token_type_ids'].squeeze(0).long(),\n",
        "                    'labels': label2encoding[self.labels[idx]]\n",
        "                    }\n",
        "\n",
        "\n",
        "        return data"
      ],
      "id": "00f35f69-d09c-4931-bb2a-298ced956dd3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3522ede-dcec-4a26-8cc1-b7e03ad5faf9"
      },
      "source": [
        "### Train, Validation set 나누기"
      ],
      "id": "d3522ede-dcec-4a26-8cc1-b7e03ad5faf9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb9fe7d4-95b8-4828-89f0-26a324fc1cab",
        "outputId": "dfc657ee-dc7e-412a-edcc-38675f36f407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset:  151826\n",
            "Validation dataset:  37957\n"
          ]
        }
      ],
      "source": [
        "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=config.train.seed)\n",
        "\n",
        "train_dataset = CustomDataset(train_data, TOKENIZER, config.train.max_seq_len, 'train')\n",
        "val_dataset = CustomDataset(val_data, TOKENIZER, config.train.max_seq_len, 'validation')\n",
        "\n",
        "print(\"Train dataset: \", len(train_dataset))\n",
        "print(\"Validation dataset: \", len(val_dataset))"
      ],
      "id": "cb9fe7d4-95b8-4828-89f0-26a324fc1cab"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abca2710-8f81-42f8-aeaf-6d6ea8b56dce"
      },
      "source": [
        "### DataLoader"
      ],
      "id": "abca2710-8f81-42f8-aeaf-6d6ea8b56dce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9a9ae26-30c4-4d50-a9df-916de91f5b69"
      },
      "outputs": [],
      "source": [
        "# torch.utils.data.DataLoader : input을 배치 단위로 리턴해주는 기능\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                                batch_size=config.train.train_batch_size,\n",
        "                                num_workers=config.train.num_workers, \n",
        "                                shuffle=True,\n",
        "                                pin_memory=True,\n",
        "                                drop_last=False)\n",
        "\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=config.train.eval_batch_size,\n",
        "                            num_workers=config.train.num_workers, \n",
        "                            shuffle=False,\n",
        "                            pin_memory=True,\n",
        "                            drop_last=False)\n"
      ],
      "id": "a9a9ae26-30c4-4d50-a9df-916de91f5b69"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f382b7f-3e20-4d01-97bd-4370b5326610"
      },
      "source": [
        "# 5. 모델 선언"
      ],
      "id": "6f382b7f-3e20-4d01-97bd-4370b5326610"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "210b17dc-5dcf-430d-89f8-ab6290fbc05f"
      },
      "outputs": [],
      "source": [
        "from transformers import logging\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# config.json 에 입력된 architecture 에 따라 베이스 모델 설정\n",
        "BASE_MODELS = {\n",
        "    \"BertForSequenceClassification\": BertForSequenceClassification,\n",
        "    \"AutoModel\": AutoModel,\n",
        "    \"ElectraForSequenceClassification\": ElectraForSequenceClassification,\n",
        "    \"AlbertForSequenceClassification\": AlbertForSequenceClassification,\n",
        "    \"RobertaForSequenceClassification\": RobertaForSequenceClassification\n",
        "}\n",
        "\n",
        "model = BASE_MODELS[config.model.architecture].from_pretrained(config.model.pretrained_model, num_labels = config.train.num_classes)\n",
        "# print(model)"
      ],
      "id": "210b17dc-5dcf-430d-89f8-ab6290fbc05f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ce1b90a-a033-4005-af89-a2f930882a7d"
      },
      "outputs": [],
      "source": [
        "# # 학습을 재개할 시 config 파일의 resume_weight_dir를 설정해주세요\n",
        "# if config.train.resume :\n",
        "#     checkpoint = torch.load(config.train.resume_weight_dir)\n",
        "#     model.load_state_dict(checkpoint['model'])"
      ],
      "id": "2ce1b90a-a033-4005-af89-a2f930882a7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb5679e8-94a3-4f65-bcbe-adbf7c033896"
      },
      "source": [
        "# 6. Optimizer"
      ],
      "id": "cb5679e8-94a3-4f65-bcbe-adbf7c033896"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25093b87-6432-4419-aa7a-346e96c339a0"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(model.parameters(), lr=config.train.learning_rate, eps=config.train.adam_epsilon)\n",
        "\n",
        "total_steps = len(train_dataloader) * config.train.num_epochs \n",
        "lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * config.train.warmup_proportion), \n",
        "                                                num_training_steps=total_steps)"
      ],
      "id": "25093b87-6432-4419-aa7a-346e96c339a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4fba02f-b593-42e2-ba7c-e3d9a70018b9"
      },
      "source": [
        "# 7. Metric"
      ],
      "id": "c4fba02f-b593-42e2-ba7c-e3d9a70018b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0de7e3dc-8575-43e8-bd9e-f708439b8f4f"
      },
      "source": [
        "- [evaluate 라이브러리 document](https://pypi.org/project/evaluate/)\n",
        "- [각 metric 사용법](https://huggingface.co/evaluate-metric?sort_spaces=alphabetical#spaces)"
      ],
      "id": "0de7e3dc-8575-43e8-bd9e-f708439b8f4f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8322e28-86fd-44b9-adb8-9e38416dc3fc"
      },
      "outputs": [],
      "source": [
        "# 사용 가능한 metric 리스트를 보려면 아래를 주석 해제하여 확인하여 config 파일을 수정하여 다시 불러오세요.\n",
        "# evaluate.list_evaluation_modules()\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    metric_fn = evaluate.load(config.train.metric)\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    if config.train.metric=='f1':\n",
        "        score = metric_fn.compute(predictions=predictions, references=labels, average='macro')\n",
        "    else:\n",
        "        score = metric_fn.compute(predictions=predictions, references=labels)\n",
        "    return score"
      ],
      "id": "a8322e28-86fd-44b9-adb8-9e38416dc3fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd3feba6-2fb9-46bf-8a64-04bc0219b8c0"
      },
      "source": [
        "# 8. Early stopper"
      ],
      "id": "cd3feba6-2fb9-46bf-8a64-04bc0219b8c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06b71842-1b9f-4b57-8273-efe8c713c52d",
        "outputId": "3193e0e4-97ce-481d-d999-908cd41732c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:train:Initiated ealry stopper, mode: min, best score: inf, patience: 2\n"
          ]
        }
      ],
      "source": [
        "from modules.earlystoppers import EarlyStopper\n",
        "\n",
        "early_stopper = EarlyStopper(patience=config.train.early_stopping_patience,\n",
        "                             mode='min',\n",
        "                             logger=logger)"
      ],
      "id": "06b71842-1b9f-4b57-8273-efe8c713c52d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a2eaa25-3368-4748-96bf-495b0b289fad"
      },
      "source": [
        "# 9. Recorder"
      ],
      "id": "6a2eaa25-3368-4748-96bf-495b0b289fad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db4b3ed5-b323-4c82-bfa3-d3e4f1d5f6e2"
      },
      "outputs": [],
      "source": [
        "from modules.recorders import Recorder\n",
        "\n",
        "recorder = Recorder(record_dir=RECORDER_DIR,\n",
        "                    model=model,\n",
        "                    optimizer=optimizer,\n",
        "                    scheduler=None,\n",
        "                    amp=None,\n",
        "                    logger=logger)"
      ],
      "id": "db4b3ed5-b323-4c82-bfa3-d3e4f1d5f6e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "b12ffc7e-7159-4082-91ce-b5d85192d3be",
        "outputId": "8a4dcefe-401a-43ba-b5e6-e116410360eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find shopping_conversation.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcheche7\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Shopping/results/train/20221019_180402/wandb/run-20221211_094017-84noyhwf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cheche7/shopping_conversation/runs/84noyhwf\" target=\"_blank\">whole-mountain-65</a></strong> to <a href=\"https://wandb.ai/cheche7/shopping_conversation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Wandb\n",
        "# Wandb 사용법은 11월 21일 곽대훈 멘토님의 강의를 참고하세요!\n",
        "if config.train.wandb:\n",
        "    \n",
        "    wandb_project_serial = 'shopping_conversation'\n",
        "    os.environ[\"WANDB_NOTEBOOK_NAME\"] = wandb_project_serial\n",
        "    wandb_username = 'cheche7' # 각자의 계정으로 수정하세요.\n",
        "    wandb.init(project=wandb_project_serial, dir=RECORDER_DIR, entity=wandb_username)\n",
        "    wandb.run.name = train_serial\n",
        "    wandb.config.update(config)\n",
        "    wandb.watch(model)\n"
      ],
      "id": "b12ffc7e-7159-4082-91ce-b5d85192d3be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1c5b3a8-a307-4a12-ab53-e1f2a7b4ac57"
      },
      "source": [
        "# 10. Trainer Class 정의\n",
        "\n",
        "### 학습 파라미터 설정\n",
        "\n",
        "- [transformers Trainer 설명](https://huggingface.co/docs/transformers/main_classes/trainer)\n",
        "- [transformers TrainingArguments 파라미터 설명](https://huggingface.co/docs/transformers/v4.23.1/en/main_classes/trainer#transformers.TrainingArguments) : Training Arguments 파라미터 설명이 기술되어 있으니 참고하시어 각 파라미터가 의미하는 바를 알아보고 조정, 혹은 추가해보세요."
      ],
      "id": "a1c5b3a8-a307-4a12-ab53-e1f2a7b4ac57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5069a877-a78e-4f1b-b7ef-d0fe7b0341d5"
      },
      "outputs": [],
      "source": [
        "# transformers에서 Trainer를 불러와서 학습에 사용할텐데, 그때 사용할 파라미터들을 미리 지정해둔다\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= RECORDER_DIR,  # output directory\n",
        "    num_train_epochs=config.train.num_epochs,  # total number of training epochs\n",
        "    resume_from_checkpoint = config.train.resume_weight_dir,\n",
        "    per_device_train_batch_size=config.train.train_batch_size,  # batch size per device during training\n",
        "    per_device_eval_batch_size=config.train.eval_batch_size,  # batch size for evaluation\n",
        "    learning_rate = config.train.learning_rate,\n",
        "    warmup_ratio = config.train.warmup_proportion,\n",
        "    weight_decay=config.train.weight_decay,\n",
        "    logging_strategy = config.train.logging_strategy,\n",
        "    # logging_steps=config.train.logging_steps, # valid when logging_strategy ='steps'\n",
        "    save_strategy=config.train.save_strategy,\n",
        "    # save_steps=config.train.save_steps, # valid when save_strategy ='steps'\n",
        "    # eval_steps=config.train.eval_steps, # valid when save_strategy ='steps'\n",
        "    do_train=True, # Perform training\n",
        "    do_eval=True, # Perform evaluation\n",
        "    evaluation_strategy = config.train.evaluation_strategy, # evalute after each epoch\n",
        "    gradient_accumulation_steps = 64,  # total number of steps before back propagation\n",
        "    fp16 = config.train.fp16, # Use mixed precision\n",
        "    run_name = train_serial, # experiment name, typically used for wandb\n",
        "    report_to=\"wandb\",  # disable wandb\n",
        "    load_best_model_at_end = True,\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    seed= config.train.seed  # Seed for experiment reproducibility\n",
        ")"
      ],
      "id": "5069a877-a78e-4f1b-b7ef-d0fe7b0341d5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e918cf04-3ebf-407b-9129-a9a7e38bbdb5"
      },
      "source": [
        "## 학습 "
      ],
      "id": "e918cf04-3ebf-407b-9129-a9a7e38bbdb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c7a57f5-d755-4446-854e-1db597ff6186"
      },
      "outputs": [],
      "source": [
        "class Run:\n",
        "\n",
        "    def __init__(self, trainer, tokenizer, training_args, test=None, submission_name = None):\n",
        "        self.trainer = trainer\n",
        "        self.tokenizer = tokenizer\n",
        "        self.training_args = training_args\n",
        "        self.test = test\n",
        "        self.submission_name = submission_name\n",
        "\n",
        "    def __call__(self):\n",
        "        if self.training_args.do_train:\n",
        "            self.train()\n",
        "\n",
        "        if self.training_args.do_eval:\n",
        "            self.validate()\n",
        "\n",
        "        if self.training_args.do_predict and self.test is not None:\n",
        "            self.predict()\n",
        "\n",
        "    def train(self):\n",
        "        self.trainer.train()\n",
        "        self.trainer.save_model()\n",
        "        if self.trainer.is_world_process_zero():\n",
        "            self.tokenizer.save_pretrained(RECORDER_DIR)\n",
        "\n",
        "    def validate(self):\n",
        "        logger.info(\"*** Evaluate ***\")\n",
        "        result = self.trainer.evaluate()\n",
        "        output_eval_file = os.path.join(RECORDER_DIR, \"eval_results.txt\")\n",
        "        if self.trainer.is_world_process_zero():\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                logger.info(\"***** Eval results *****\")\n",
        "                for key, value in result.items():\n",
        "                    logger.info(\"%s = %s\", key, value)\n",
        "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
        "\n",
        "        logger.info(\"Validation set result : {}\".format(result))\n",
        "\n",
        "    # 추론 함수\n",
        "    def predict(self):\n",
        "        logger.info(\"*** Test ***\")\n",
        "        predictions = self.trainer.predict(test_dataset=self.test)\n",
        "        test_df['speechAct'] = self.prediction(predictions.predictions)\n",
        "        test_df.to_csv(self.submission_name, index=False)\n",
        "        test_df.sort_values(by='sentence_id', ascending=True)\n",
        "        print(\"Submission file saved as :\", self.submission_name)\n",
        "\n",
        "    def prediction(self,logit):\n",
        "        labels = np.argmax(logit, axis=1)\n",
        "        return list(map(lambda x: encoding2label[x], labels))"
      ],
      "id": "5c7a57f5-d755-4446-854e-1db597ff6186"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41713ea4-857c-4b92-bea5-3b71acffcbe5"
      },
      "source": [
        "# 11. Trainer 선언"
      ],
      "id": "41713ea4-857c-4b92-bea5-3b71acffcbe5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98c42f52-cebe-4e5b-be0f-0bd454eae118",
        "outputId": "1cb461c3-cfcb-43c8-9f3f-738938acbda5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "# Trainer\n",
        "from transformers import Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "# Set trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "callbacks=[EarlyStoppingCallback(early_stopping_patience=config.train.early_stopping_patience)]\n",
        "\n",
        ")\n",
        "\n",
        "# Set runner\n",
        "train = Run(\n",
        "    training_args=training_args,\n",
        "    trainer=trainer,\n",
        "    tokenizer=TOKENIZER,\n",
        "    )"
      ],
      "id": "98c42f52-cebe-4e5b-be0f-0bd454eae118"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "249c24f0-e0a4-40cd-aabb-17c30ae48e29"
      },
      "source": [
        "# 12. 학습"
      ],
      "id": "249c24f0-e0a4-40cd-aabb-17c30ae48e29"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a77bb51-345b-4a39-b840-014a475a2d49",
        "outputId": "83d48a9a-fe9d-4b0e-ffea-c00b5ccbb6dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 151826\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2048\n",
            "  Gradient Accumulation steps = 64\n",
            "  Total optimization steps = 370\n",
            "  Number of trainable parameters = 336670734\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 37957\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.8224, 'learning_rate': 8.338028169014085e-05, 'epoch': 1.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-74\n",
            "Configuration saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-74/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.534602165222168, 'eval_f1': 0.5187044945686227, 'eval_runtime': 218.9306, 'eval_samples_per_second': 173.375, 'eval_steps_per_second': 5.422, 'epoch': 1.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-74/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-222] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 37957\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.5148, 'learning_rate': 6.253521126760565e-05, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-148\n",
            "Configuration saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-148/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5170103311538696, 'eval_f1': 0.5493392387885896, 'eval_runtime': 218.8314, 'eval_samples_per_second': 173.453, 'eval_steps_per_second': 5.424, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-148/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-296] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 37957\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.4655, 'learning_rate': 4.1690140845070425e-05, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-222\n",
            "Configuration saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-222/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5127819180488586, 'eval_f1': 0.5320473912790674, 'eval_runtime': 218.9583, 'eval_samples_per_second': 173.353, 'eval_steps_per_second': 5.421, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-222/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-370] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 37957\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.4153, 'learning_rate': 2.0845070422535212e-05, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-296\n",
            "Configuration saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-296/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5286005735397339, 'eval_f1': 0.562328156642362, 'eval_runtime': 219.0053, 'eval_samples_per_second': 173.315, 'eval_steps_per_second': 5.42, 'epoch': 4.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-296/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-74] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 37957\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.3584, 'learning_rate': 0.0, 'epoch': 5.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-370\n",
            "Configuration saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-370/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5588827133178711, 'eval_f1': 0.5605111398970889, 'eval_runtime': 218.8559, 'eval_samples_per_second': 173.434, 'eval_steps_per_second': 5.424, 'epoch': 5.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-370/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-148] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/Shopping/results/train/20221019_180402/checkpoint-222 (score: 0.5127819180488586).\n",
            "Saving model checkpoint to /content/drive/MyDrive/Shopping/results/train/20221019_180402\n",
            "Configuration saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_runtime': 14148.68, 'train_samples_per_second': 53.654, 'train_steps_per_second': 0.026, 'train_loss': 0.515282713400351, 'epoch': 5.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model weights saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Shopping/results/train/20221019_180402/special_tokens_map.json\n",
            "INFO:train:*** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 37957\n",
            "  Batch size = 32\n",
            "INFO:train:***** Eval results *****\n",
            "INFO:train:eval_loss = 0.5127819180488586\n",
            "INFO:train:eval_f1 = 0.5320473912790674\n",
            "INFO:train:eval_runtime = 219.7114\n",
            "INFO:train:eval_samples_per_second = 172.758\n",
            "INFO:train:eval_steps_per_second = 5.403\n",
            "INFO:train:epoch = 5.0\n",
            "INFO:train:Validation set result : {'eval_loss': 0.5127819180488586, 'eval_f1': 0.5320473912790674, 'eval_runtime': 219.7114, 'eval_samples_per_second': 172.758, 'eval_steps_per_second': 5.403, 'epoch': 5.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.5127819180488586, 'eval_f1': 0.5320473912790674, 'eval_runtime': 219.7114, 'eval_samples_per_second': 172.758, 'eval_steps_per_second': 5.403, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "train()"
      ],
      "id": "5a77bb51-345b-4a39-b840-014a475a2d49"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "285debfc-3ce7-4390-a18d-80f201db00c6"
      },
      "source": [
        "# 13. 추론 \n",
        "### 추론 config 설정"
      ],
      "id": "285debfc-3ce7-4390-a18d-80f201db00c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5563f210-e27e-43d9-8976-db11c2835530"
      },
      "outputs": [],
      "source": [
        "# Load config\n",
        "predict_config_path = os.path.join(PROJECT_DIR, 'baseline', 'config', 'predict.yaml')\n",
        "predict_config = OmegaConf.load(predict_config_path)"
      ],
      "id": "5563f210-e27e-43d9-8976-db11c2835530"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48db8e84-12a5-46e8-a2b9-145de1efae81"
      },
      "source": [
        "### 추론을 로깅할 디렉토리 생성"
      ],
      "id": "48db8e84-12a5-46e8-a2b9-145de1efae81"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19554fa0-94dc-429f-a746-07ea7c5bbf74"
      },
      "outputs": [],
      "source": [
        "# Serial\n",
        "if predict_config['predict']['train_serial'] is None:\n",
        "    train_serial = os.path.basename(RECORDER_DIR)\n",
        "else:\n",
        "    train_serial = predict_config['predict']['train_serial']\n",
        "    \n",
        "\n",
        "# Predict directory\n",
        "PREDICT_DIR = os.path.join(RECORDER_DIR, 'predict')\n",
        "os.makedirs(PREDICT_DIR, exist_ok=True)"
      ],
      "id": "19554fa0-94dc-429f-a746-07ea7c5bbf74"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bd89362-3398-4012-a0e9-fb2857ec3936"
      },
      "source": [
        "### 데이터 경로 지정"
      ],
      "id": "3bd89362-3398-4012-a0e9-fb2857ec3936"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3185cfc6-836d-4bf9-843b-0536e97dc19e"
      },
      "outputs": [],
      "source": [
        "# Data Directory\n",
        "DATA_DIR = predict_config['predict']['dataset_path']"
      ],
      "id": "3185cfc6-836d-4bf9-843b-0536e97dc19e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33acd73e-f0ab-42d7-b2a1-33945eeaf097"
      },
      "source": [
        "### 테스트 데이터셋 및 데이터 로더 선언\n"
      ],
      "id": "33acd73e-f0ab-42d7-b2a1-33945eeaf097"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3339dd2d-8afd-4743-bb0e-dff6acfa86f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe59782-f178-43aa-e1df-1ce06bcb016f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset:  20520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "test_df = make_df(TEST_DIR, test=True)\n",
        "test_df['order']=test_df['sentence_id'].str.split('-')\n",
        "\n",
        "for i in range(len(test_df)):\n",
        "    test_df['order'][i][1]=int(test_df['order'][i][1])\n",
        "\n",
        "test_df.sort_values(by='order',inplace=True)\n",
        "test_df.reset_index(inplace=True)\n",
        "test_df.drop(['index', 'order'], axis=1, inplace=True)\n",
        "# test_df.drop(['index', 'speaker', 'order'], axis=1, inplace=True)\n",
        "\n",
        "test_dataset = CustomDataset(test_df, TOKENIZER, config.train.max_seq_len, 'test')\n",
        "print(\"Test dataset: \", len(test_dataset))\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                            batch_size=predict_config.predict.batch_size,\n",
        "                            num_workers=predict_config.predict.num_workers,\n",
        "                            shuffle=False,\n",
        "                            pin_memory=True,\n",
        "                            drop_last=False)"
      ],
      "id": "3339dd2d-8afd-4743-bb0e-dff6acfa86f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f05fa197-1a67-4c44-b2f0-8a68ae5e2901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "dd17aa40-b45d-4bef-9626-5bd3e8573f18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            sentence_id speaker                                   text\n",
              "0       test_0001.txt-0       A          안녕하십니까 #@소속# 에어컨 상담사 #@이름#입니다\n",
              "1       test_0001.txt-1       A                    제가 말씀 못 드린 부분이 있어서요\n",
              "2       test_0001.txt-2       A  혹시 냉매가 부족한 경우에는 냉매보충비가 별도로 나올 수가 있습니다\n",
              "3       test_0001.txt-3       B                         가스 추가 말씀하시는 거죠\n",
              "4       test_0001.txt-4       B                      가스 추가는 보통 얼마나 하나요\n",
              "...                 ...     ...                                    ...\n",
              "20515   test_1456.txt-8       A                        내일 언제쯤 연락을 드릴까요\n",
              "20516   test_1456.txt-9       B                    다섯시 이후에는 가능할 거 같습니다\n",
              "20517  test_1456.txt-10       A         네 그럼 내일 다섯시 반에 다시 연락드리겠습니다 고객님\n",
              "20518  test_1456.txt-11       B                          네 감사합니다 수고하세요\n",
              "20519  test_1456.txt-12       A                        네 고객님 좋은 하루 되세요\n",
              "\n",
              "[20520 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a3c8fba-59fc-497d-b261-4ab9d18c7455\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0001.txt-0</td>\n",
              "      <td>A</td>\n",
              "      <td>안녕하십니까 #@소속# 에어컨 상담사 #@이름#입니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_0001.txt-1</td>\n",
              "      <td>A</td>\n",
              "      <td>제가 말씀 못 드린 부분이 있어서요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_0001.txt-2</td>\n",
              "      <td>A</td>\n",
              "      <td>혹시 냉매가 부족한 경우에는 냉매보충비가 별도로 나올 수가 있습니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_0001.txt-3</td>\n",
              "      <td>B</td>\n",
              "      <td>가스 추가 말씀하시는 거죠</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_0001.txt-4</td>\n",
              "      <td>B</td>\n",
              "      <td>가스 추가는 보통 얼마나 하나요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20515</th>\n",
              "      <td>test_1456.txt-8</td>\n",
              "      <td>A</td>\n",
              "      <td>내일 언제쯤 연락을 드릴까요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20516</th>\n",
              "      <td>test_1456.txt-9</td>\n",
              "      <td>B</td>\n",
              "      <td>다섯시 이후에는 가능할 거 같습니다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20517</th>\n",
              "      <td>test_1456.txt-10</td>\n",
              "      <td>A</td>\n",
              "      <td>네 그럼 내일 다섯시 반에 다시 연락드리겠습니다 고객님</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20518</th>\n",
              "      <td>test_1456.txt-11</td>\n",
              "      <td>B</td>\n",
              "      <td>네 감사합니다 수고하세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20519</th>\n",
              "      <td>test_1456.txt-12</td>\n",
              "      <td>A</td>\n",
              "      <td>네 고객님 좋은 하루 되세요</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20520 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a3c8fba-59fc-497d-b261-4ab9d18c7455')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a3c8fba-59fc-497d-b261-4ab9d18c7455 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a3c8fba-59fc-497d-b261-4ab9d18c7455');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "test_df"
      ],
      "id": "f05fa197-1a67-4c44-b2f0-8a68ae5e2901"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25426e0d-bae3-43d2-b9a6-30e3c30aa041",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef92db9-f1e5-4ae2-ae41-5d205c7e9021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/Shopping/results/train/20221019_180402/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"klue/roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"tokenizer_class\": \"BertTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/Shopping/results/train/20221019_180402/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/Shopping/results/train/20221019_180402.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "model = BASE_MODELS[config.model.architecture].from_pretrained(RECORDER_DIR)\n",
        "\n",
        "predicting_args = TrainingArguments(\n",
        "        run_name=train_serial,\n",
        "        disable_tqdm=False,\n",
        "        per_device_eval_batch_size = predict_config.predict.batch_size,\n",
        "        fp16=config.train.fp16,\n",
        "        gradient_accumulation_steps=64,\n",
        "        do_train=False,\n",
        "        do_eval=False,\n",
        "        do_predict=True,\n",
        "        output_dir='.',\n",
        "    )\n",
        "\n",
        "trainer_prediction = Trainer(\n",
        "    model= model,\n",
        "    args=predicting_args\n",
        ")\n",
        "\n",
        "predict = Run(\n",
        "    training_args=predicting_args,\n",
        "    trainer=trainer_prediction,\n",
        "    tokenizer=TOKENIZER,\n",
        "    test=test_dataset,\n",
        "    submission_name = predict_config.predict.submission_name\n",
        "    )"
      ],
      "id": "25426e0d-bae3-43d2-b9a6-30e3c30aa041"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7128ec25-87df-443c-9421-fccbb069b8c0"
      },
      "source": [
        "## 추론"
      ],
      "id": "7128ec25-87df-443c-9421-fccbb069b8c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd8c58b1-b713-40b1-877f-04a04a164a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "b3e05d8f-b1af-4627-bbf8-36dbe950ba92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:train:*** Test ***\n",
            "***** Running Prediction *****\n",
            "  Num examples = 20520\n",
            "  Batch size = 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved as : submission.csv\n"
          ]
        }
      ],
      "source": [
        "predict()"
      ],
      "id": "bd8c58b1-b713-40b1-877f-04a04a164a7e"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "79b2fe59-0197-44ed-8ba7-68c988b2747f",
        "7ce4062a-7030-4a06-9ec1-985a9e7bd49e",
        "dIiEaoZLN-qY",
        "d3522ede-dcec-4a26-8cc1-b7e03ad5faf9",
        "abca2710-8f81-42f8-aeaf-6d6ea8b56dce",
        "48db8e84-12a5-46e8-a2b9-145de1efae81",
        "3bd89362-3398-4012-a0e9-fb2857ec3936",
        "33acd73e-f0ab-42d7-b2a1-33945eeaf097"
      ],
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}